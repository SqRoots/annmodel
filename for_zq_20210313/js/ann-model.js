const bigmath = math.create(math.all, {
  number: 'BigNumber', // Choose 'number' (default), 'BigNumber', or 'Fraction'
  precision: 256        // 64 by default, only applicable for BigNumbers
})
// ===========================================================================
// 定义计算神经网络的函数
// evaluate ann
function eval_ann(ann_input){
  // 从表单读取输入数据 ann_input
  // form_agrs = $('#form_agrs').serializeArray();
  // var ann_input = [];
  // for (k in form_agrs){
  //   ann_input.push([parseFloat(form_agrs[k].value)])
  // }
  for (var i=0,len=ann_input.length; i<len; i++){
    if (ann_input[i]==''){
      return null
    }
  }

  // 计算神经网络，输入数据标准化
  // console.log(ann_input);
  var standard_input = math.dotDivide(math.subtract(ann_input,data_mean),data_std);
  // standard_input = LogisticSigmoid(standard_input);
  standard_input.push([1]);
  // console.log(standard_input);

  // 输入不做标准化，也不使用 LogisticSigmoid 处理
  // standard_input = ann_input;	// 向量
  // standard_input.push([1]);		// 增补末尾的 1

  // 计算神经网络，隐藏层1
  ann_layer_1_out = math.multiply(ann_layer_1,standard_input);	// 输入→输出
  ann_layer_1_out.pop();										// 去掉末尾的 1
  ann_layer_1_out = Ramp(ann_layer_1_out);						// 使用激活函数
  ann_layer_1_out.push([1]);									// 增补末尾的 1，得到最终输出

  // 计算神经网络，隐藏层2
  ann_layer_2_out = math.multiply(ann_layer_2,ann_layer_1_out);	// 输入→输出
  ann_layer_2_out.pop();										// 去掉末尾的 1
  ann_layer_2_out = Ramp(ann_layer_2_out);						// 使用激活函数
  ann_layer_2_out.push([1]);									// 增补末尾的 1，得到最终输出

  // 计算神经网络，隐藏层3
  ann_layer_3_out = math.multiply(ann_layer_3,ann_layer_2_out);
  ann_layer_3_out.pop();

  // 计算神经网络，输出层
  sm = SoftMax2(ann_layer_3_out);

  // 返回结果
  return sm[0]  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}


// ===========================================================================
// 定义常用的激活函数（有些可能未被使用）
// 激活函数（Activation Function）LogisticSigmoid
function LogisticSigmoid(x_matrix){
  return math.dotDivide(1,math.add(1,math.exp(math.unaryMinus(x_matrix))))
}
// console.log(LogisticSigmoid([1,2,3]));

// 激活函数（Activation Function）Ramp
function Ramp(x_matrix){
  const a = math.matrix(x_matrix);
  const b = a.map(function (value, index, matrix) {
    return Math.max(0,value)
  });
  return b["_data"];
}

// 激活函数（Activation Function）SoftMax
function SoftMax(x_matrix){
  x = math.flatten(x_matrix);
  return math.divide(math.exp(x),math.multiply(math.ones(math.size(x)),math.exp(x)))  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}
// console.log(SoftMax([1,2,3]));

// 激活函数（Activation Function）SoftMax2 (仅适用于2分类模型，即x_matrix为2行1列，解决大数计算问题)
function SoftMax2(x_matrix){
  x = math.flatten(x_matrix);
  return [1/(1+math.exp(x[1]-x[0])),1/(1+math.exp(x[0]-x[1]))]  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}
// console.log(SoftMax([1,2,3]));

// ===========================================================================
// const parser = math.parser()
// // 激活函数（Activation Function）
// parser.eval('LogisticSigmoid(x) = 1./(1.+e.^(-x))')
// console.log(parser.eval('LogisticSigmoid([1,2,3])'));
//
//
// // SoftMax
// parser.eval('SoftMax(x) = e.^(x)./(ones(size(x)[1])*(e.^(x)))')
// console.log(parser.eval('SoftMax([1,2,3])'));
// ===========================================================================


// 均值
var data_mean = [
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000]
];

//标准差
var data_std = [
[ 342515.2183489400000],
[ 68810258.14691100000],
[ 2466715.954980000000],
[ 5854099.250621000000],
[ 45484.09352097299000],
[ 94365.69809400000000],
[ 254197.0771300200000],
[ 61467.14570934100000],
[ 55603.41583239000000],
[ 5916610.751785184000],
[ 3367309.215262851000]
];

//输入→隐藏层1，Weight+Biases
var ann_layer_1 = [
[ 0.2893089354038239, 0.4921184778213501,-0.8918115496635440, 0.1669514328241348, 2.1196265220642090, 0.6321177482604980, 1.0612888336181640, 0.0623663179576397,-0.4293000102043152, 0.2892110943794250,-0.6568877696990967, 0.0337767712771893],
[-0.0993024408817291,-0.5195236802101135, 1.1243622303009030,-0.1648710966110230,-2.2152621746063230,-0.6506737470626831,-1.1616297960281370,-0.1523677855730057, 0.4915170371532440,-0.1128481253981590, 0.7197343111038208, 0.1821187585592270],
[-0.1618813425302505, 0.5630341768264770,-2.1465311050415040,-0.5008245706558228, 3.9723474979400630, 1.1955139636993410,-1.7891885042190550,-4.3095431327819820, 0.8067976832389830, 0.5789487361907959, 0.5774293541908264,-0.0288571063429117],
[ 0.3417027294635773, 1.0205864906311040,-1.2664731740951540, 0.3716859519481659, 2.1621832847595210, 0.7228989005088806, 1.2964341640472410, 0.0758793130517006,-0.5098098516464233, 0.2439873665571213,-0.8507617712020870, 0.0574209801852703],
[-0.1290629506111145,-0.3917733132839203, 0.9159044027328490,-0.1000095978379250,-1.4493308067321780,-0.3400926887989044,-0.7508476972579956,-0.0928156599402428, 0.3518190085887909,-0.1546882688999176, 0.5233321189880371, 0.1779018491506577],
[-0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000,-0.0000000000000000],
[ 0.2692083120346069, 0.3675065934658050,-1.1930586099624630, 0.2230417728424072, 2.3349757194519040, 0.9825511574745180, 1.3189384937286380,-0.0223500132560730,-0.5771904587745667, 0.1734698265790939,-0.8534368276596070, 0.0738727897405624],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];

//输入→隐藏层2，Weight+Biases
var ann_layer_2 = [
[-1.6893346309661870, 1.8114924430847170, 6.2954587936401370,-1.7959405183792110, 1.2505949735641480,-0.0000000000000000,-2.1072640419006350, 0.1203109472990036],
[-1.5636152029037480, 1.5839617252349850, 6.2611002922058100,-2.0180835723876950, 0.9877342581748960,-0.0000000000000000,-1.7894314527511600, 0.1645234674215317],
[-0.0000000000000000,-0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000,-0.0000000000000000,-0.0000000000000000,-0.0000000000000000],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];

//输入→隐藏层3，Weight+Biases
var ann_layer_3 = [
[ 5.0502142906188960, 5.4947533607482910, 0.0000000000000000,-1.7286425828933720],
[-4.8568067550659180,-5.0969080924987790, 0.0000000000000000, 1.7286478281021120],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];
