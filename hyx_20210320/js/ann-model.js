// ===========================================================================
// 定义计算神经网络的函数
// evaluate ann
function eval_ann(ann_input){
  // 从表单读取输入数据 ann_input
  // form_agrs = $('#form_agrs').serializeArray();
  // var ann_input = [];
  // for (k in form_agrs){
  //   ann_input.push([parseFloat(form_agrs[k].value)])
  // }
  for (var i=0,len=ann_input.length; i<len; i++){
    if (typeof(ann_input[i])=="undefined"||ann_input[i]==''){
      return null
    }
  }

  // 计算神经网络，输入数据标准化
  // console.log(ann_input);
  var standard_input = math.dotDivide(math.subtract(ann_input,data_mean),data_std);
  // standard_input = LogisticSigmoid(standard_input);
  standard_input.push([1]);
  // console.log(standard_input);

  // 输入不做标准化，也不使用 LogisticSigmoid 处理
  // standard_input = ann_input;	// 向量
  // standard_input.push([1]);		// 增补末尾的 1

  // 计算神经网络，隐藏层1
  ann_layer_1_out = math.multiply(ann_layer_1,standard_input);	// 输入→输出
  ann_layer_1_out.pop();										// 去掉末尾的 1
  ann_layer_1_out = Ramp(ann_layer_1_out);						// 使用激活函数
  ann_layer_1_out.push([1]);									// 增补末尾的 1，得到最终输出

  // 计算神经网络，隐藏层2
  ann_layer_2_out = math.multiply(ann_layer_2,ann_layer_1_out);	// 输入→输出
  ann_layer_2_out.pop();										// 去掉末尾的 1
  ann_layer_2_out = Ramp(ann_layer_2_out);						// 使用激活函数
  ann_layer_2_out.push([1]);									// 增补末尾的 1，得到最终输出

  // 计算神经网络，隐藏层3
  ann_layer_3_out = math.multiply(ann_layer_3,ann_layer_2_out);
  ann_layer_3_out.pop();

  // 计算神经网络，输出层
  sm = SoftMax2(ann_layer_3_out);

  // 返回结果，阴性概率
  return sm[0]  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}


// ===========================================================================
// 定义常用的激活函数（有些可能未被使用）
// 激活函数（Activation Function）LogisticSigmoid
function LogisticSigmoid(x_matrix){
  return math.dotDivide(1,math.add(1,math.exp(math.unaryMinus(x_matrix))))
}
// console.log(LogisticSigmoid([1,2,3]));

// 激活函数（Activation Function）Ramp
function Ramp(x_matrix){
  const a = math.matrix(x_matrix);
  const b = a.map(function (value, index, matrix) {
    return Math.max(0,value)
  });
  return b["_data"];
}

// 激活函数（Activation Function）SoftMax
function SoftMax(x_matrix){
  x = math.flatten(x_matrix);
  return math.divide(math.exp(x),math.multiply(math.ones(math.size(x)),math.exp(x)))
}
// console.log(SoftMax([1,2,3]));

// 激活函数（Activation Function）SoftMax2 (仅适用于2分类模型，即x_matrix为2行1列，解决大数计算问题)
function SoftMax2(x_matrix){
  x = math.flatten(x_matrix);
  return [1/(1+math.exp(x[1]-x[0])),1/(1+math.exp(x[0]-x[1]))]  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}
// console.log(SoftMax2([1,2,3]));

// ===========================================================================
// const parser = math.parser()
// // 激活函数（Activation Function）
// parser.eval('LogisticSigmoid(x) = 1./(1.+e.^(-x))')
// console.log(parser.eval('LogisticSigmoid([1,2,3])'));
//
//
// // SoftMax
// parser.eval('SoftMax(x) = e.^(x)./(ones(size(x)[1])*(e.^(x)))')
// console.log(parser.eval('SoftMax([1,2,3])'));
// ===========================================================================


// 均值
var data_mean = [
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000]
];

//标准差
var data_std = [
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000]
];

//输入→隐藏层1，Weight+Biases
var ann_layer_1 = [
[ 0.3512253463268280,-0.0290473140776157,-2.1712195873260500, 0.4988273978233337,-0.6830415725708008,-1.4672183990478520,-0.9870853424072270,-0.3365572094917297, 0.1658712625503540,-0.1839557588100433, 0.2044722437858582,-0.1474666446447372, 0.4819363057613373],
[ 0.6165034174919128, 0.2049138247966766, 1.8980166912078860, 1.1022075414657590,-0.2303939312696457, 1.6306430101394650,-2.2224400043487550,-0.3053370714187622, 0.0678596943616867, 0.8245540857315060,-0.0274827256798744, 0.5438464879989624, 0.2607311010360718],
[ 0.0027057349216193,-1.8985573053359990, 0.3314613997936249, 0.1673277467489243, 0.6150142550468445,-2.3986396789550780,-2.9191148281097410,-0.3266467452049255, 0.1647277623414993,-0.4043363928794861, 0.2521145939826965,-0.5709368586540222,-0.6344156265258789],
[-1.1283934116363530,-1.8392316102981570,-0.0912678614258766,-0.4459477663040161,-1.0495578050613400,-1.0165584087371830,-0.5327191948890686, 0.1820826232433319, 0.0268429517745972, 0.3708267509937286,-0.7295692563056946,-0.7532130479812622,-0.3425694704055786],
[-0.5068424940109253, 0.1165762841701508,-0.2412674129009247,-0.3111273944377899,-0.2388648986816406, 0.6426998972892761,-0.7755758762359619, 0.1422202289104462, 0.3616844415664673,-0.5675657391548157,-0.0277865510433912,-0.4916363656520844,-0.1648825556039810],
[-0.2677628397941589,-0.1230702474713326,-0.3383451998233795,-0.7137947082519531, 0.1352695226669312, 0.1700978577136993, 0.0211547110229731, 0.5735756754875183, 0.2364116162061691, 0.2280584573745728,-0.0105686960741878,-0.9087157845497130,-0.0262480601668358],
[-1.6856788396835330,-0.1638576537370682, 1.4882822036743160,-0.5108500719070435, 0.6912060379981995, 0.9280855655670170, 1.4005054235458370, 0.0068846703507006, 0.3297302126884460,-0.3948629498481750,-0.2504409551620483, 0.1022465303540230, 0.2300188690423965],
[ 0.2275848239660263,-1.3571102619171140, 0.0241952240467072, 1.2287294864654540,-0.9094607830047610,-0.7981680631637573, 0.3164601325988770, 0.2282847017049789, 0.0677870735526085, 0.7495100498199463,-0.2916553020477295,-0.4226087629795074, 1.9128564596176150],
[-0.4739453792572021,-0.2681550383567810, 0.0316382907330990,-1.0249165296554570,-1.1741249561309810,-0.8597965240478520,-0.0124622117727995,-0.0232943277806044,-0.2372458875179291, 0.1505027413368225, 0.1338339895009995, 0.3802548050880432, 0.2917462587356567],
[-0.2344336062669754,-1.8023096323013310,-0.3865290880203247, 1.4499351978302000, 1.1329436302185060,-1.4360942840576170, 0.8712814450263980,-0.3174328207969666, 0.0134235182777047,-0.2149760574102402, 0.0502735115587711, 0.7653049826622009, 0.5026884078979492],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];

//输入→隐藏层2，Weight+Biases
var ann_layer_2 = [
[ 0.0000000000000000,-0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000,-0.0000000000000000,-0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000, 0.0000000000000000],
[-0.2700846195220947, 0.2005987167358398, 0.7294142246246338, 1.1976779699325560, 0.3151465654373169, 0.0371936261653900,-0.6233827471733093,-0.3880158662796020, 1.6873848438262940, 1.1816676855087280,-0.8209661841392520],
[-0.6103932857513428,-2.6142547130584720, 1.0854490995407100,-0.0098742106929421, 0.0984542593359947,-0.0721547082066536,-0.3830224275588989, 0.6573593020439148,-0.8396742939949040, 1.1582872867584230, 2.0147378444671630],
[-0.0000000000000000,-0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000, 0.0000000000000000,-0.0000000000000000,-0.0000000000000000],
[ 0.5707941651344299, 1.0844649076461790,-0.3251425027847290, 1.0135198831558230,-0.4277354478836060, 0.3982922732830048,-0.5887028574943542, 0.5038025379180908, 0.1932535767555237, 1.0333392620086670, 0.4058441221714020],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];

//输入→隐藏层3，Weight+Biases
var ann_layer_3 = [
[ 0.0000000000000000, 3.9451551437377930, 1.5575553178787230,-0.0000000000000000,-0.8166728615760800,-0.1562272608280182],
[ 0.0000000000000000,-3.9467353820800780,-1.2349182367324830, 0.0000000000000000, 0.3798094689846039, 0.1562422364950180],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];
