// ===========================================================================
// 定义计算神经网络的函数
// evaluate ann
function eval_ann(ann_input){
  // 从表单读取输入数据 ann_input
  // form_agrs = $('#form_agrs').serializeArray();
  // var ann_input = [];
  // for (k in form_agrs){
  //   ann_input.push([parseFloat(form_agrs[k].value)])
  // }
  for (var i=0,len=ann_input.length; i<len; i++){
    if (typeof(ann_input[i])=="undefined"||ann_input[i]==''){
      return null
    }
  }

  // 计算神经网络，输入数据标准化
  // console.log(ann_input);
  var standard_input = math.dotDivide(math.subtract(ann_input,data_mean),data_std);
  // standard_input = LogisticSigmoid(standard_input);
  standard_input.push([1]);
  // console.log(standard_input);

  // 输入不做标准化，也不使用 LogisticSigmoid 处理
  // standard_input = ann_input;	// 向量
  // standard_input.push([1]);		// 增补末尾的 1

  // 计算神经网络，隐藏层1
  ann_layer_1_out = math.multiply(ann_layer_1,standard_input);	// 输入→输出
  ann_layer_1_out.pop();										// 去掉末尾的 1
  ann_layer_1_out = Ramp(ann_layer_1_out);						// 使用激活函数
  ann_layer_1_out.push([1]);									// 增补末尾的 1，得到最终输出

  // 计算神经网络，隐藏层2
  ann_layer_2_out = math.multiply(ann_layer_2,ann_layer_1_out);	// 输入→输出
  ann_layer_2_out.pop();										// 去掉末尾的 1
  ann_layer_2_out = Ramp(ann_layer_2_out);						// 使用激活函数
  ann_layer_2_out.push([1]);									// 增补末尾的 1，得到最终输出

  // 计算神经网络，隐藏层3
  ann_layer_3_out = math.multiply(ann_layer_3,ann_layer_2_out);
  ann_layer_3_out.pop();

  // 计算神经网络，输出层
  sm = SoftMax2(ann_layer_3_out);

  // 返回结果，阴性概率
  return sm[0]  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}


// ===========================================================================
// 定义常用的激活函数（有些可能未被使用）
// 激活函数（Activation Function）LogisticSigmoid
function LogisticSigmoid(x_matrix){
  return math.dotDivide(1,math.add(1,math.exp(math.unaryMinus(x_matrix))))
}
// console.log(LogisticSigmoid([1,2,3]));

// 激活函数（Activation Function）Ramp
function Ramp(x_matrix){
  const a = math.matrix(x_matrix);
  const b = a.map(function (value, index, matrix) {
    return Math.max(0,value)
  });
  return b["_data"];
}

// 激活函数（Activation Function）SoftMax
function SoftMax(x_matrix){
  x = math.flatten(x_matrix);
  return math.divide(math.exp(x),math.multiply(math.ones(math.size(x)),math.exp(x)))
}
// console.log(SoftMax([1,2,3]));

// 激活函数（Activation Function）SoftMax2 (仅适用于2分类模型，即x_matrix为2行1列，解决大数计算问题)
function SoftMax2(x_matrix){
  x = math.flatten(x_matrix);
  return [1/(1+math.exp(x[1]-x[0])),1/(1+math.exp(x[0]-x[1]))]  // [阴性概率，阳性概率，这与训练模型中定义有关："output" -> NetDecoder[{"Class", {0, 1}}]]
}
// console.log(SoftMax2([1,2,3]));

// ===========================================================================
// const parser = math.parser()
// // 激活函数（Activation Function）
// parser.eval('LogisticSigmoid(x) = 1./(1.+e.^(-x))')
// console.log(parser.eval('LogisticSigmoid([1,2,3])'));
//
//
// // SoftMax
// parser.eval('SoftMax(x) = e.^(x)./(ones(size(x)[1])*(e.^(x)))')
// console.log(parser.eval('SoftMax([1,2,3])'));
// ===========================================================================


// 均值
var data_mean = [
[ 37.2468982630273000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 0.0000000000000000],
[ 297.3740074441687000],
[ 162.6072661290323000],
[ 4.6187510402219150],
[ 168.0720872274143000],
[ 5.7235359801488840]
];

//标准差
var data_std = [
[ 10.6478457819398700],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 1.0000000000000000],
[ 387.5519075310841000],
[ 226.8939230923263000],
[ 1.2157919999849730],
[ 54.0670744054628100],
[ 1.8484033146817150]
];

//输入→隐藏层1，Weight+Biases
var ann_layer_1 = [
[ 0.7728334069252014,-0.3362455070018768,-0.3458368778228760, 0.0838690921664238,-0.2046884745359421,-0.3196842074394226, 0.1820117235183716,-0.1588390618562698,-0.4265793561935425, 0.2262896001338959],
[ 0.2104890048503876,-0.3530423641204834,-0.0145189026370645,-0.1057139784097672, 0.3873714506626129, 0.2619507014751434, 0.1011824086308479, 0.4608883857727051, 0.1336599439382553, 0.0409657955169678],
[ 0.3113014400005341,-0.1598584949970245,-0.0330158434808254, 0.2381883263587952, 0.0302503723651171, 0.3484890758991241, 0.2889972925186157,-0.0760333612561226,-0.3009650707244873,-0.0283211153000593],
[ 0.2490902841091156,-0.1329670101404190, 0.3608815968036652, 0.1913912296295166, 0.7753291726112366,-0.0315211638808250, 0.1166516095399857, 0.2204556614160538, 0.1981134116649628, 0.0995831117033958],
[-0.2613751292228699,-0.2720425724983215, 0.3710787296295166, 0.0147029934450984,-0.4281477332115173,-0.4675615429878235, 0.1779506951570511,-0.5334167480468750, 0.9675242304801940, 0.2313563823699951],
[-0.6202929019927979,-0.1835889667272568, 0.2116000056266785, 0.0999326631426811,-0.1647313982248306,-0.2842304110527039, 0.1217182204127312, 0.6021366119384766, 0.1078439429402351, 0.2736217975616455],
[-0.0678636506199837,-0.2689457237720490, 0.0494987666606903,-0.2210526913404465, 0.0949635058641434, 0.2246313989162445,-0.1069176718592644, 0.2567694187164307,-0.4926401674747467, 0.1493783742189407],
[ 0.6881963014602661, 0.8735154271125790,-0.0838107243180275, 0.2558254301548004,-0.1041863039135933,-0.7608358860015869, 0.3615806400775909, 0.0122769419103861,-0.1194103881716728, 0.2049499452114105],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];

//输入→隐藏层2，Weight+Biases
var ann_layer_2 = [
[-0.0188066400587559,-0.0269096847623587, 0.2919024527072906, 0.3894742131233215, 0.8041728734970090, 0.6502237319946289, 0.4557795226573944,-0.7070764899253845,-0.0005264908540994],
[-0.4984919428825378, 0.3808721601963043, 0.5311645865440369, 0.8611091971397400, 0.8103103041648870, 0.5146190524101257, 0.2464576065540314,-0.2137317359447479, 0.0001283426681766],
[ 0.7996750473976135, 0.3882449567317963, 0.4183354079723358,-0.1343996077775955,-0.6457410454750061, 0.0847001299262047, 0.4199364185333252,-0.5180147886276245, 0.0000047180510592],
[-0.1057968363165855, 0.1590396016836166, 0.1204959303140640, 0.2251106500625610, 0.1944408714771271, 0.1486159861087799, 0.0716161653399468,-0.0810452401638031, 0.0004804894560948],
[ 0.3921386599540710,-0.6693229675292969,-0.2137206792831421,-0.0778870433568955, 0.3561377227306366,-0.0264019370079041,-0.1388648897409439, 0.5899738669395447, 0.3471630513668060],
[ 0.1180178672075272, 0.0610511712729931, 0.1025821268558502, 0.0754316374659538, 0.1765185594558716, 0.0903934836387634, 0.0268836263567209,-0.1042802408337593,-0.0016671067569405],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];

//输入→隐藏层3，Weight+Biases
var ann_layer_3 = [
[ 1.0686315298080440, 0.2281869500875473, 0.7492079734802246, 0.0280610639601946,-0.8338944315910340,-0.0713558867573738,-0.1834568828344345],
[-0.7285005450248718,-1.2196605205535890,-0.5993361473083496,-0.4224697053432465, 0.1078554391860962,-0.2192679047584534, 0.1834567934274673],
[ 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 0.0000000000000000, 1.0000000000000000]
];
